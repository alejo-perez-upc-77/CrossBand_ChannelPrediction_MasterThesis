---
title: "Preprocessing + PPCA"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r include=FALSE}
library(R.matlab)
library(BiocManager)
library(pcaMethods)
library(MetabolAnalyze)
library(MASS)
library(abind)
```

##  Load Data from csv 

```{r }

UE1 <- as.matrix(read.csv('../data2UEjoint/data_unfold_UE1_600.csv', row.names = 1))
UE2 <- as.matrix(read.csv('../data2UEjoint/data_unfold_UE2_600.csv', row.names = 1))

masked_data_UE1 <- as.matrix(read.csv('../data2UEjoint/masked_data_UE1.csv', row.names = 1))
masked_data_UE2 <- as.matrix(read.csv('../data2UEjoint/masked_data_UE2.csv'))[,c(-1,-2)]

len_masked <- sum(apply(masked_data_UE1, 1, anyNA))


```

## Preprocessing 

We receive the data in a shape [x x x] and subsequently unfold it into a matrix  [`r dim(data)`]. We also separate Imaginary and Real part. Therefore, `r dim(data)[2]`/4 corresponds to the number of Multipath Components for each of the 4 sub-bands. Afterwards we split the `r dim(data)[1]` into a training and validation set, 60% and and 40% of the rows respectively. We mask the validation set with hiding 3 of the bands and liberating 1 each time. The pattern for the masking is freeing bands in this fashion: 1, 3, 2, 4 .

```{r include=FALSE}

split <- function(masked_data, len_masked){
  
  # Split Train and Validation Data in terms of the mask length 
  
  train <- masked_data[1:(nrow(masked_data) - len_masked), ]
  
  valid <- masked_data[(nrow(masked_data) - len_masked + 1):nrow(masked_data), ]
  
  list(train=train, valid=valid)
} 

train_valid_UE1 <- split(masked_data_UE1, len_masked)
train_valid_UE2 <- split(masked_data_UE2, len_masked)

train_UE1 <- train_valid_UE1$train
valid_UE1 <- train_valid_UE1$valid

train_UE2 <- train_valid_UE2$train
valid_UE2 <- train_valid_UE2$valid


train_valid_unmasked_UE1  <- split(UE1, len_masked)
train_valid_unmasked_UE2  <- split(UE2, len_masked)

valid_unmask_UE1 <- train_valid_unmasked_UE1$valid
valid_unmask_UE2 <- train_valid_unmasked_UE2$valid

train <- rbind(train_UE1, train_UE2)
valid <- rbind(valid_UE1, valid_UE2)

valid_unmask <- rbind(valid_unmask_UE1, valid_unmask_UE2)

```




### PPCA Extraction + Prediction in validation set

Here below our implementation will be outlined. We separate training (without NaNs) and validation (with NaNs) dataset. We estimate covariance parameters of the PPCA via the EM algorithm PCA of the package function feeding the training dataset to it. Later on, variance is estimated taking the variance of the noise when we reconstruct the training dataset by performing the **cross product of scores and loadings obtained from the PPCA**.

#### PPCA

```{r }

# Extract PCA, Latent variables and \mu vector from training data

fit_ppca <- function(train, Pcs=10, method="ppca"){
  
  # PCAs
  ppca_ <-  pca(train, nPcs=Pcs, method="ppca")

  # Latent Varible aka Sigma in MVNorm
  pc_scores <- scores(ppca_)
  
  # Contribution of each observation to each the Latent variable
  pc_loadings <- loadings(ppca_)
  
  # \mu vector. Mass Center
  pc_mu <- center(ppca_)
  
  # Estimated Noise
  epsilon <- (fitted(ppca_)-train)
  
  train_reconstructed <- fitted(ppca_)
  
  # Estimated Noise Variance
  var_eps <- var(c(epsilon))

  return(list(pc_scores = pc_scores,pc_loadings = pc_loadings, pc_mu = pc_mu, epsilon = epsilon, var_eps = var_eps))
  
}

ppca_ <- fit_ppca(train, Pcs=12, method="ppca")

pc_scores <- ppca_$pc_scores
pc_loadings <- ppca_$pc_loadings
pc_mu <- ppca_$pc_mu
epsilon <- ppca_$epsilon
var_eps <- ppca_$var_eps

```
Then the prediction on the missing values is done following the formulas specified in the notes.

```{r, include=FALSE}
chol_inv <- function(A){
  chol2inv(chol(A))
}


pc.predict_1_sample <- function(sample, mu, Sigma, var_eps){
  
  # This function predicts the missing data for one sample x_i by means of the 
  # conditional predictive distribution
  
  # Split Observations x_i
  obs_ind <- which(!is.na(sample))
  mis_ind <- which(is.na(sample))
  
  sample_obs <- sample[obs_ind]
  
  # Split Mus
  mu_obs <- mu[obs_ind]
  mu_mis <- mu[mis_ind]
  
  # Split Sigma (W)
  Sigma_obs <- Sigma[obs_ind, ]
  Sigma_mis <- Sigma[mis_ind, ]
  
  # chol2inv(chol(M)) where M is cov matrix 
  
  # Compute x_mis|x_obs
  # Tolerance for the solve
  sample[mis_ind] <- mu_mis + Sigma_mis %*% chol_inv(t(Sigma_obs) %*% Sigma_obs + var_eps*diag(ncol(Sigma_obs))) %*%  t(Sigma_obs) %*%  (sample_obs - mu_obs) 
  
  #Sigma_cond <- var_eps * Sigma_mis %*% solve(t(Sigma_obs) %*% Sigma_obs + var_eps*diag(ncol(Sigma_obs))) %*% t(Sigma_mis) + var_eps*diag(nrow(Sigma_mis))
  sample
  
}

pc.predict <- function(valid_set, mu, Sigma, var_eps){
  
  # Run pc.predict_1_sample for all functions
  
  val_pred <- apply(valid_set, 1, pc.predict_1_sample, mu, Sigma, var_eps)
  t(val_pred)
  
}
```

```{r }
missing <- is.na(valid)

valid_pred  <- pc.predict(valid, pc_mu, pc_loadings, var_eps)

#valid_pred_var_cond <- pc.predict_varcond(valid, pc_mu, pc_loadings, var_eps)

# TO DO: Fix this, add mean just to predicted val 
#data_rec_postpro <- prep(valid_pred, scl(ppca_), center(ppca_), reverse=TRUE) 




```
A plot is performed to show how the actual predicted values correlate with the predictions. The red dots correspond to the post-processing data (summing the centered means). *The pre-processing and post processing to be discussed in my own implementation due to loadings and scores use post processing in the creation of PPCA*.

```{r , echo=FALSE}

# Corrected_Abs_SE <- sqrt(mean((valid_unmask[missing] - valid_pred[missing]))^2 / var(valid_unmask[missing]))

# Jinliangs
corrected_Abs_SE <- sqrt(mean(abs(valid_unmask[missing] - valid_pred[missing])^2) / mean(abs(valid_unmask[missing])^2))

MAE <- mean(abs(valid_unmask[missing] - valid_pred[missing]))
RMSE <- sqrt(mean((valid_unmask[missing] - valid_pred[missing])^2))
MSE <- mean((valid_unmask[missing] - valid_pred[missing])^2)
```



```{r , echo=FALSE}

table <- matrix(c(corrected_Abs_SE, MAE, RMSE, MSE), 1, 4)
rownames(table) <- c("Error Metric")
colnames(table) <- c("NRMSE", "MAE", "RMSE", "MSE")

knitr::kable(table)

plot(valid_unmask[missing], valid_pred[missing], col='blue',
       main="Hold-out Prediction PPCA JointDS", ylab= 'Prediction', 
     xlab= 'Background Truth') 
  

#+points(valid_unmask[missing], valid_pred[missing], col='red' ) 

#legend(1,95, legend=c("Predictions", "Post-Processed prediction"),
      # col=c("red", "blue"), lty=1:2, cex=0.8)

```

### BPCA Extraction + Prediction in validation set

Some fix has to be done here to the library because the features are very much correlated and they use solve to invert huge covariance matrices.

```{r, echo=FALSE}
#```{r }

################################################################################
######################## system is computationally r############################
#######################singular: reciprocal condition number####################
################################################################################

## Extract BPCA, Latent variables and \mu vector from training data
#
## BPCAs
bpca_ <-  pca(train, nPcs=12, method="bpca")
#
## Latent Varible aka Sigma in MVNorm
pc_scores <- scores(bpca_)
#
## Contribution of each observation to each the Latent variable
pc_loadings <- loadings(bpca_)
#
## \mu vector. Mass Center
pc_mu <- center(bpca_)
#
## Estimated Noise
epsilon <- (completeObs(bpca_)-train)
#
## Estimated Noise Variance
var_eps <- var(c(epsilon))
#
#
valid_pred  <- pc.predict(valid, pc_mu, pc_loadings, var_eps)
#data_rec_postpro <- prep(valid_pred, scl(ppca_), center(ppca_), reverse=TRUE) 
#
#
corrected_Abs_SE <- sqrt(mean(abs(valid_unmask[missing] - valid_pred[missing])^2) / mean(abs(valid_unmask[missing])^2))
#
MAE <- mean(abs(valid_unmask[missing] - valid_pred[missing]))
RMSE <- sqrt(mean((valid_unmask[missing] - valid_pred[missing])^2))
MSE <- mean((valid_unmask[missing] - valid_pred[missing])^2)
#
```
```{r, echo=FALSE }
#```{r }
table <- matrix(c(corrected_Abs_SE, MAE, RMSE, MSE), 1, 4)
rownames(table) <- c("Error Metric")
colnames(table) <- c("NRMSE", "MAE", "RMSE", "MSE")
#
knitr::kable(table)
#
plot(valid_unmask[missing], valid_pred[missing], col='red', ylab= 'Prediction', 
     xlab= 'Background Truth', main="Hold-out Prediction BPCA JointDS") 
  # + points(valid_unmask[missing], data_rec_postpro[missing], col='blue') 
#
#legend(1,95, legend=c("Predictions", "Post-Processed prediction"),
#       col=c("red", "blue"), lty=1:2, cex=0.8)
#  
#
```

### Grid Search PPCA

```{r }
itNum <- 40
  
NRMSE_vec <-  rep(NaN, itNum)

for (k in 2:itNum){
  #
  print(k)
  ppca_ <- fit_ppca(train, Pcs=k, method="ppca")
  
  pc_scores <- ppca_$pc_scores
  pc_loadings <- ppca_$pc_loadings
  pc_mu <- ppca_$pc_mu
  var_eps <- ppca_$var_eps
  
  valid_pred  <- pc.predict(valid, pc_mu, pc_loadings, var_eps)



  corrected_Abs_SE <- sqrt(mean(abs(valid_unmask[missing] - valid_pred[missing])^2) / mean(abs(valid_unmask[missing])^2))

  NRMSE_vec[k-1] <- corrected_Abs_SE
    
   # MAE <- mean(abs(valid_unmask[missing] - valid_pred[missing]))
 # RMSE <- sqrt(mean((valid_unmask[missing] - valid_pred[missing])^2))
 # MSE <- mean((valid_unmask[missing] - valid_pred[missing])^2)

  }

plot(2:(itNum), NRMSE_vec[2:length(NRMSE_vec)])

NRMSE_vec  
```

```{r }

# Generate X values NN

X <- t(apply(masked_data, function(x) x[!is.na(x)], MARGIN = 1))
masked_idx <- is.na(masked_data)

# Generate y Values for NN

y <- matrix(nrow = nrow(X), ncol=3*(ncol(masked_data)/4))
  
for (i in 1:nrow(masked_idx)){
  idx_row <- which(masked_idx[i,])
  row <- data[i,idx_row]
  y[i,] <- row
}

#write.csv(X, '../data_UE1_600/X_600_TTI.csv')
#write.csv(y, '../data_UE1_600/y_600_TTI.csv')
```


### Grid Search PPCA
```{r }
a = pca(train, nPcs=40, method="ppca")
plot(a@R2, main='% of explained variance per number of PPCs')
points(which.min(a@R2), min(a@R2), col="red")
```

```{r, echo=FALSE, warning = FALSE, message = FALSE}
################################################################################
################ Fitting distributions on the predicted error ##################
################################################################################

fitdistnorm <- fitdistr(c(valid_pred[missing] - valid_unmask[missing]), densfun = "normal")
fitdistt <- fitdistr(c(valid_pred[missing] - valid_unmask[missing]), densfun = "t")

x <- seq(-.5, .5, length=1000)

normfit <- dnorm(x, fitdistnorm$estimate[[1]], fitdistnorm$estimate[[2]])
hx <- dnorm(x, fitdistnorm$estimate[[1]], fitdistnorm$estimate[[2]])

tfit <- dt(x, df =  fitdistt$estimate[[3]])
yvals <- dt((c(valid_pred[missing]- valid_unmask[missing]) - fitdistt$estimate[[1]])/fitdistt$estimate[[2]], 
            df = fitdistt$estimate[[3]])/fitdistt$estimate[[2]]

################################# Plots ########################################

hist(c(valid_pred[missing]- valid_unmask[missing]), breaks = 1500, probability = TRUE, main = 'Histogram of the Error of prediction error of PPCA (JointDS)', xlim=c(-.4, .4))
lines(x, hx,type = 'l', # density plot ,
      col = "red", cex=2)
points((c(valid_pred[missing]- valid_unmask[missing])), yvals, cex=.25, col='green')
legend("topright", legend=c("MLE Student-T", "MLE Normal"),
       col=c("green", "red"), lty=c(1,1), cex=0.8)



```
