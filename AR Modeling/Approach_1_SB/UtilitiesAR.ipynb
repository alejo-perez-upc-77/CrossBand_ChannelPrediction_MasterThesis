{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842f5eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy as np\n",
    "import pandas as  pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "#import keras\n",
    "import matplotlib.pyplot as plt \n",
    "from tensorflow.keras import layers\n",
    "from sklearn import *\n",
    "import math\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "tf.autograph.set_verbosity(0)\n",
    "from sklearn import linear_model as lm  # Used for solving linear regression problems\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "import cmath\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8683c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reIm2complex_sb(sbi):\n",
    "    \n",
    "  # It takes a matrix of 1 subband but Re and Im part concatenated. It merges \n",
    "  # them together into a complex subband of MPCs\n",
    "  \n",
    "  # Inputs\n",
    "  # sbi: matrix [tti x p·2]\n",
    "  \n",
    "  # Outputs\n",
    "  # sbfold: matrix [tti x p]\n",
    "  \n",
    "\n",
    "    ncol_out = int(sbi.shape[1]/2)\n",
    "    nrow_out = int(sbi.shape[0])\n",
    "\n",
    "    sbfold = np.empty([(nrow_out), (ncol_out)], dtype = 'complex_')\n",
    "    sbi = sbi.values\n",
    "    for i in range((ncol_out)):\n",
    "        \n",
    "        sbfold[:, i] = np.array([r * (math.cos(phi) + math.sin(phi)*1j) for r, phi in zip(sbi[:, i], sbi[:, i+ncol_out])])\n",
    "        \n",
    "    return sbfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b606f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fold_matrix <- function(unfold_mat){\n",
    "#  # It takes an unfold matrix of MPCs and returns a forded one\n",
    "#  \n",
    "#  # Inputs\n",
    "#  # sbi: matrix [tti x p·2·sb]\n",
    "#  \n",
    "#  # Outputs\n",
    "#  # sbfold: matrix [p  x sb x tti]\n",
    "#  \n",
    "#  sb = 4\n",
    "#  sbcolreim <- ncol(unfold_mat)/sb\n",
    "#  nrows_sb <- nrow(unfold_mat)\n",
    "#  \n",
    "#  p <- sbcolreim/2\n",
    "#  \n",
    "#  sb1 <- unfold_mat[, 1:sbcolreim]\n",
    "#  sb2 <- unfold_mat[, (sbcolreim+ 1) : (2*sbcolreim)]\n",
    "#  sb3 <- unfold_mat[, (2*sbcolreim + 1) : (3*sbcolreim)]\n",
    "#  sb4 <- unfold_mat[, (3*sbcolreim + 1) : ncol(unfold_mat)]\n",
    "#  \n",
    "#  sb1_fold <- reIm2complex_sb(sb1) \n",
    "#  sb2_fold <- reIm2complex_sb(sb2) \n",
    "#  sb3_fold <- reIm2complex_sb(sb3) \n",
    "#  sb4_fold <- reIm2complex_sb(sb4) \n",
    "#  \n",
    "#  fold_mat <-  sb1_fold\n",
    "#  fold_mat <- abind(fold_mat, sb2_fold, along = 3)\n",
    "#  fold_mat <- abind(fold_mat, sb3_fold, along = 3)\n",
    "#  fold_mat <- abind(fold_mat, sb4_fold, along = 3)\n",
    "#  \n",
    "#  aperm(fold_mat, c(2,3,1))\n",
    "#  \n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d148530b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ar_1step(theta, y_target):\n",
    "    \"\"\"Predicts the value y_t for t = p+1, ..., n, for an AR(p) model, based on the data in y_target using\n",
    "    one-step-ahead prediction.\n",
    "\n",
    "    :param theta: array (p,), AR coefficients, theta=(a1,a2,...,ap).\n",
    "    :param y_target: array (n,), the data points used to compute the predictions.\n",
    "    :return y_pred: array (n-p,), the one-step predictions (\\hat y_{p+1}, ...., \\hat y_n) \n",
    "    \"\"\"\n",
    "\n",
    "    n = len(y_target)\n",
    "    p = theta.shape[1]\n",
    "    \n",
    "    # Number of steps in prediction\n",
    "    m = n-p\n",
    "    y_pred = np.zeros(m+1)\n",
    "    for i in range(m):\n",
    "        y_pred[i] =  (np.flip(y_target[i:i+p]) * theta).sum()\n",
    "        \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f95f507",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_ar(y, p):\n",
    "    \"\"\"Fits an AR(p) model. The loss function is the sum of squared errors from t=p+1 to t=n.\n",
    "\n",
    "    :param y: array (n,), training data points\n",
    "    :param p: int, AR model order\n",
    "    :return theta: array (p,), learnt AR coefficients\n",
    "    \"\"\"\n",
    "\n",
    "    # Number of training data points\n",
    "    n = y.shape[0]\n",
    "    \n",
    "    # Construct the regression matrix\n",
    "    Phi = np.zeros((n-p, p))# <COMPLETE THIS LINE>\n",
    "    for j in range(p):\n",
    "        Phi[:,j] = y[(p-(j+1)): (n-(j+1)), 0] # <COMPLETE THIS LINE>\n",
    "    \n",
    "    # Drop the first p values from the target vector y\n",
    "    yy = y[p:]  # yy = (y_{t+p+1}, ..., y_n)\n",
    "\n",
    "    # Here we use fit_intercept=False since we do not want to include an intercept term in the AR model\n",
    "    regr = lm.LinearRegression(fit_intercept=False)\n",
    "    regr.fit(Phi,yy)    \n",
    "\n",
    "    return regr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0d71b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_validation(mpc, y_pred, X_test):\n",
    "    \n",
    "    valid_reconstruct = np.empty((y_pred.shape[0], mpc*8,))\n",
    "\n",
    "    indexes = np.arange(mpc * 8)\n",
    "\n",
    "    idx_sb1 = np.arange(0,(mpc*2))\n",
    "    idx_sb2 = np.arange((mpc*2),(mpc*4))\n",
    "   \n",
    "\n",
    "    idx_sb1_dis = np.array(list(set(indexes) - set(idx_sb1)))\n",
    "    idx_sb2_dis = np.array(list(set(indexes) - set(idx_sb2)))\n",
    "   \n",
    "    sb_counter_1 = 0\n",
    "    sb_counter_2 = -1\n",
    "   \n",
    "    for i in range(y_pred.shape[0],):\n",
    "\n",
    "        if sb_counter_1%4==0:\n",
    "\n",
    "            valid_reconstruct[i, idx_sb1] = X_test[i,:]\n",
    "            valid_reconstruct[i, idx_sb1_dis] = y_pred[i,:]\n",
    "\n",
    "        elif sb_counter_2%4==0:\n",
    "\n",
    "            valid_reconstruct[i, idx_sb2] = X_test[i,:]\n",
    "            valid_reconstruct[i, idx_sb2_dis] = y_pred[i,:]\n",
    "\n",
    "        sb_counter_1 += 1\n",
    "        sb_counter_2 += 1\n",
    "        \n",
    "    return valid_reconstruct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8124cc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def acf(x, lags=None):\n",
    "    \"\"\" Computes the empirical autocorralation function.\n",
    "    :param x: array (n,), sequence of data points\n",
    "    :param lags: int, maximum lag to compute the ACF for. If None, this is set to n-1. Default is None.\n",
    "    :return gamma: array (lags,), values of the ACF at lags 0 to lags\n",
    "    \"\"\"\n",
    "\n",
    "    gamma = np.correlate(x, x, mode='full')  # Size here is always 2*len(x)-1\n",
    "    gamma = gamma[int((gamma.size - 1) / 2):]  # Keep only second half\n",
    "    if lags is not None and lags < len(gamma):\n",
    "        gamma = gamma[0:lags + 1]\n",
    "    return gamma / gamma[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967fc3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "def acfplot(x, lags=None, conf=0.95):\n",
    "    \"\"\"Plots the empirical autocorralation function.\n",
    "    :param x: array (n,), sequence of data points\n",
    "    :param lags: int, maximum lag to compute the ACF for. If None, this is set to n-1. Default is None.\n",
    "    :param conf: float, number in the interval [0,1] which specifies the confidence level (based on a central limit\n",
    "                 theorem under a white noise assumption) for two dashed lines drawn in the plot. Default is 0.95.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    n = len(x)\n",
    "    y = acf(x, lags)\n",
    "    lags = len(y)\n",
    "    \n",
    "    lag_vec = np.arange(lags)\n",
    "    \n",
    "    c = norm.isf((1-conf)/2,loc=0,scale=1/np.sqrt(n)) # Use inverse survival function (=1-cdf) at half the confidence interval\n",
    "    plt.plot(lag_vec,c*np.ones(lags),'k--',linewidth=1, label=f\"{100*conf}% confidence\")\n",
    "    plt.plot(lag_vec,-c*np.ones(lags),'k--',linewidth=1)\n",
    "    \n",
    "    plt.stem(lag_vec, y, linefmt='-', markerfmt=' ', basefmt=\"k \", use_line_collection=True, label=\"Empirical ACF\")\n",
    "    plt.plot(lag_vec, 0*lag_vec, 'k-')\n",
    "    plt.title(f\"Empirical ACF\")\n",
    "    plt.legend() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4571c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nrmse(y_pred, y_test):\n",
    "    \n",
    "    num = tf.math.reduce_sum(tf.square(y_pred - y_test))\n",
    "    num = num / y_test.shape[1]\n",
    "    \n",
    "    den = tf.math.reduce_sum(tf.square(y_test))/y_test.shape[1]\n",
    "    \n",
    "    return (num/den).numpy()\n",
    "\n",
    "def mse(y_pred, y_test):\n",
    "    \n",
    "    num = tf.math.reduce_sum(tf.square(y_pred - y_test))\n",
    "    num = num / y_test.shape[1]\n",
    "    \n",
    "    return num.numpy()\n",
    "\n",
    "def mae(y_pred, y_test):\n",
    "    \n",
    "    num = tf.math.reduce_sum(tf.abs(y_pred - y_test))\n",
    "    num = num / y_test.shape[1]\n",
    "    \n",
    "    return num.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35292320",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_test(history, name_ds):\n",
    "    \n",
    "    plt_1 = plt.figure(figsize=(6, 3))\n",
    "\n",
    "    plt.plot(history.history['MSE'])\n",
    "    #plt.plot(history.history['val_total_loss'])\n",
    "    plt.ylabel('Loss', fontsize ='xx-large')\n",
    "    plt.xlabel('epoch', fontsize ='xx-large')\n",
    "    plt.plot(history.history['val_MSE_val'])\n",
    "\n",
    "    plt.legend(['train', 'test'], loc='upper center', fontsize ='12')\n",
    "    plt.title('Model Loss During Training {}'.format(name_ds), fontsize='xx-large')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dc5d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def  plot_pred_vs_true(y_pred, y_test, name_ds):\n",
    "    \n",
    "    plt_1 = plt.figure(figsize=(6, 3))\n",
    "    plt.scatter(y_test.flatten(), y_pred.flatten(), s=2)\n",
    "    plt.title('VED Predictions {}'.format(name_ds), fontsize='xx-large')\n",
    "    plt.ylabel('Prediction', fontsize ='xx-large')\n",
    "    plt.xlabel('Background Truth', fontsize ='xx-large')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483f37ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sorted_vs_true(y_pred, y_test, name_ds):\n",
    "\n",
    "    plt_1 = plt.figure(figsize=(10, 6))\n",
    "\n",
    "    plt.plot(np.sort(y_test.flatten()))\n",
    "    x_idx = np.arange(len(y_test.flatten()))\n",
    "    plt.scatter(x_idx, y_pred.flatten()[np.argsort(y_test.flatten())], s=2, c=\"red\")\n",
    "\n",
    "    plt.title('Sorted Predictions of Validation Set {}'.format(name_ds), fontsize='xx-large')\n",
    "    plt.ylabel('Prediction', fontsize ='xx-large')\n",
    "    plt.xlabel('Background Truth', fontsize ='xx-large')\n",
    "    plt.legend(['Sorted Background Truth', 'Predictions'], loc='upper right', fontsize ='xx-large')\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66611cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_1TTI(y_test, y_pred, X_test, samp_num, name_ds): \n",
    "\n",
    "    plt_1 = plt.figure(figsize=(10, 6))\n",
    "    sample_1 = np.r_[ y_test[samp_num,], X_test[samp_num,]]\n",
    "    idx = np.arange(len(sample_1))\n",
    "    plt.scatter(np.arange(len(sample_1)), sample_1, s=2, c=\"black\")\n",
    "    plt.scatter(idx[-len(y_pred[samp_num,]):], y_pred[samp_num,], color='red',  s=2)\n",
    "    plt.title('Prediction of TTI n={} {}'.format(samp_num, name_ds) , fontsize ='xx-large')\n",
    "    plt.legend(['Background Truth', 'Predictions'],labelcolor = ['black', 'red'] ,loc='upper right', fontsize ='xx-large')\n",
    "    plt.ylabel('Feature', fontsize ='xx-large')\n",
    "    plt.xlabel('Amplitude', fontsize ='xx-large')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e572fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_MPC_overtime(data, mpc, name_ds, Real):\n",
    "    \n",
    "    if Real:\n",
    "        plt.plot(data[:,0], label='1st MPC SB1')\n",
    "        plt.plot(data[:, mpc*2], label='1st MPC SB2')\n",
    "        plt.plot(data[:, mpc*4], label='1st MPC SB3')\n",
    "        plt.plot(data[:, mpc*6], label='1st MPC SB4')\n",
    "\n",
    "\n",
    "        plt.title('plot of 1st MPC in 4 subbands Over Time (Real Part) {}'.format(name_ds),  fontsize='xx-large')\n",
    "        plt.xlabel('TTI', fontsize='xx-large')\n",
    "        plt.ylabel('Amplitude', fontsize='xx-large')\n",
    "        plt.legend(fontsize='xx-large')\n",
    "        plt.tight_layout()\n",
    "        plt.show() \n",
    "    \n",
    "    else:\n",
    "        plt.plot(data[:,mpc], label='1st MPC SB1')\n",
    "        plt.plot(data[:,mpc*3], label='1st MPC SB2')\n",
    "        plt.plot(data[:,mpc*5], label='1st MPC SB3')\n",
    "        plt.plot(data[:,mpc*7], label='1st MPC SB4')\n",
    "\n",
    "\n",
    "        plt.title('plot of 1st MPC in 4 subbands Over Time (Imaginary Part) {}'.format(name_ds),  fontsize='xx-large')\n",
    "        plt.xlabel('TTI', fontsize='xx-large')\n",
    "        plt.ylabel('Amplitude', fontsize='xx-large')\n",
    "        plt.legend(fontsize='xx-large')\n",
    "        plt.tight_layout()\n",
    "        plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358727c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NMSE(true_chan, pred_chan):\n",
    "    \n",
    "    chann_diff = true_chan - pred_chan\n",
    "    \n",
    "    num = (np.sqrt(sum(sum(((chann_diff.conj().T).dot(chann_diff))**2)))).real\n",
    "    den = (np.sqrt(sum(sum(((true_chan.conj().T).dot(true_chan))**2)))).real\n",
    "    \n",
    "    return num/den\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
