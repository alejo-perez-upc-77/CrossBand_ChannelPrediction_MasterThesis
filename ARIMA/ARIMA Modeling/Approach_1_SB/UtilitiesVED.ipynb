{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "842f5eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy as np\n",
    "import pandas as  pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "#import keras\n",
    "import matplotlib.pyplot as plt \n",
    "from tensorflow.keras import layers\n",
    "from sklearn import *\n",
    "import math\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "tf.autograph.set_verbosity(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c0d71b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_validation(mpc, y_pred, X_test):\n",
    "    \n",
    "    valid_reconstruct = np.empty((y_pred.shape[0], mpc*8,))\n",
    "\n",
    "    indexes = np.arange(mpc * 8)\n",
    "\n",
    "    idx_sb1 = np.arange(0,(mpc*2))\n",
    "    idx_sb2 = np.arange((mpc*2),(mpc*4))\n",
    "   \n",
    "\n",
    "    idx_sb1_dis = np.array(list(set(indexes) - set(idx_sb1)))\n",
    "    idx_sb2_dis = np.array(list(set(indexes) - set(idx_sb2)))\n",
    "   \n",
    "    sb_counter_1 = 0\n",
    "    sb_counter_2 = -1\n",
    "   \n",
    "    for i in range(y_pred.shape[0],):\n",
    "\n",
    "        if sb_counter_1%4==0:\n",
    "\n",
    "            valid_reconstruct[i, idx_sb1] = X_test[i,:]\n",
    "            valid_reconstruct[i, idx_sb1_dis] = y_pred[i,:]\n",
    "\n",
    "        elif sb_counter_2%4==0:\n",
    "\n",
    "            valid_reconstruct[i, idx_sb2] = X_test[i,:]\n",
    "            valid_reconstruct[i, idx_sb2_dis] = y_pred[i,:]\n",
    "\n",
    "        sb_counter_1 += 1\n",
    "        sb_counter_2 += 1\n",
    "        \n",
    "    return valid_reconstruct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "967fc3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def m2tex(model,modelName):\n",
    "    stringlist = []\n",
    "    model.summary(line_length=70, print_fn=lambda x: stringlist.append(x))\n",
    "    del stringlist[1:-4:2]\n",
    "    del stringlist[-1]\n",
    "    for ix in range(1,len(stringlist)-3):\n",
    "        tmp = stringlist[ix]\n",
    "        stringlist[ix] = tmp[0:31]+\"& \"+tmp[31:59]+\"& \"+tmp[59:]+\"\\\\\\\\ \\hline\"\n",
    "    stringlist[0] = \"Model: {} \\\\\\\\ \\hline\".format(modelName)\n",
    "    stringlist[1] = stringlist[1]+\" \\hline\"\n",
    "    stringlist[-4] += \" \\hline\"\n",
    "    stringlist[-3] += \" \\\\\\\\\"\n",
    "    stringlist[-2] += \" \\\\\\\\\"\n",
    "    stringlist[-1] += \" \\\\\\\\ \\hline\"\n",
    "    prefix = [\"\\\\begin{table}[]\", \"\\\\begin{tabular}{lll}\"]\n",
    "    suffix = [\"\\end{tabular}\", \"\\caption{{Model summary for {}.}}\".format(modelName), \"\\label{tab:model-summary}\" , \"\\end{table}\"]\n",
    "    stringlist = prefix + stringlist + suffix \n",
    "    out_str = \" \\n\".join(stringlist)\n",
    "    out_str = out_str.replace(\"_\", \"\\_\")\n",
    "    out_str = out_str.replace(\"#\", \"\\#\")\n",
    "    print(out_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "900b2c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim)) # Parametrization trick\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d70a7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, KL_hyperparam, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.KL_hyperparam = KL_hyperparam\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")  #MEAN? \n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(    #MEAN? \n",
    "            name=\"MSE\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")   #MEAN? \n",
    "        \n",
    "        self.total_loss_tracker_val = keras.metrics.Mean(name=\"total_loss_val\")  #MEAN? \n",
    "        self.reconstruction_loss_tracker_val = keras.metrics.Mean(    #MEAN? \n",
    "            name=\"MSE_val\"\n",
    "        )\n",
    "        self.kl_loss_tracker_val = keras.metrics.Mean(name=\"kl_loss_val\")   #MEAN? \n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "            \n",
    "            self.total_loss_tracker_val,\n",
    "            self.reconstruction_loss_tracker_val,\n",
    "            self.kl_loss_tracker_val\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        x, y_true = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(x)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = keras.losses.mean_squared_error(y_true, reconstruction)\n",
    "            \n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            #kl_loss = tf.reduce_mean(kl_loss, axis=1)\n",
    "            \n",
    "            total_loss = reconstruction_loss + kl_loss * self.KL_hyperparam\n",
    "            \n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        \n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        \n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        \n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        \n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"MSE\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "\n",
    "    def test_step(self, data):\n",
    "        # Unpack the data\n",
    "        x, y_true = data\n",
    "        # Compute predictions\n",
    "        z_mean, z_log_var, z = self.encoder(x)\n",
    "        reconstruction = self.decoder(z)\n",
    "        \n",
    "        ## Losses\n",
    "        reconstruction_loss = keras.losses.mean_squared_error(y_true, reconstruction)\n",
    "        \n",
    "        kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "        kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "        \n",
    "        total_loss = reconstruction_loss + kl_loss * self.KL_hyperparam\n",
    "\n",
    "        # Updates the metrics tracking the loss\n",
    "        self.total_loss_tracker_val.update_state(total_loss)\n",
    "        \n",
    "        self.reconstruction_loss_tracker_val.update_state(reconstruction_loss)\n",
    "        \n",
    "        self.kl_loss_tracker_val.update_state(kl_loss)\n",
    "        \n",
    "        return {\n",
    "            \"loss_val\": self.total_loss_tracker_val.result(),\n",
    "            \"MSE_val\": self.reconstruction_loss_tracker_val.result(),\n",
    "            \"kl_loss_val\": self.kl_loss_tracker_val.result(),\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        z_mean, z_log_var, z = self.encoder(inputs)\n",
    "        reconstruction = self.decoder(z)\n",
    "                \n",
    "\n",
    "\n",
    "        return reconstruction\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4571c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nrmse(y_pred, y_test):\n",
    "    \n",
    "    num = tf.math.reduce_sum(tf.square(y_pred - y_test))\n",
    "    num = num / y_test.shape[1]\n",
    "    \n",
    "    den = tf.math.reduce_sum(tf.square(y_test))/y_test.shape[1]\n",
    "    \n",
    "    return (num/den).numpy()\n",
    "\n",
    "def mse(y_pred, y_test):\n",
    "    \n",
    "    num = tf.math.reduce_sum(tf.square(y_pred - y_test))\n",
    "    num = num / y_test.shape[1]\n",
    "    \n",
    "    return num.numpy()\n",
    "\n",
    "def mae(y_pred, y_test):\n",
    "    \n",
    "    num = tf.math.reduce_sum(tf.abs(y_pred - y_test))\n",
    "    num = num / y_test.shape[1]\n",
    "    \n",
    "    return num.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88b91632",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mse_loss(history, name_ds):\n",
    "    plt.plot(history.history['MSE'])\n",
    "    plt.title('MSE Training Loss {}'.format(name_ds), fontsize ='xx-large')\n",
    "    plt.xlabel('Epoch', fontsize ='xx-large')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3150a0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_kl_mse(history, name_ds):\n",
    "    plt.plot(history.history['kl_loss'])\n",
    "    #plt.plot(history.history['val_total_loss'])\n",
    "    plt.title('Model Training Set Loss {}'.format(name_ds), fontsize ='xx-large')\n",
    "    plt.ylabel('Loss', fontsize ='xx-large')\n",
    "    plt.xlabel('epoch', fontsize ='xx-large')\n",
    "    plt.plot(history.history['MSE'])\n",
    "    plt.legend(['KL_loss', 'MSE'], loc='upper right', fontsize ='xx-large')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35292320",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_test(history, name_ds):\n",
    "    \n",
    "    plt_1 = plt.figure(figsize=(6, 3))\n",
    "\n",
    "    plt.plot(history.history['MSE'])\n",
    "    #plt.plot(history.history['val_total_loss'])\n",
    "    plt.ylabel('Loss', fontsize ='xx-large')\n",
    "    plt.xlabel('epoch', fontsize ='xx-large')\n",
    "    plt.plot(history.history['val_MSE_val'])\n",
    "\n",
    "    plt.legend(['train', 'test'], loc='upper center', fontsize ='12')\n",
    "    plt.title('Model Loss During Training {}'.format(name_ds), fontsize='xx-large')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1dc5d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def  plot_pred_vs_true(y_pred, y_test, name_ds):\n",
    "    \n",
    "    plt_1 = plt.figure(figsize=(6, 3))\n",
    "    plt.scatter(y_test.flatten(), y_pred.flatten(), s=2)\n",
    "    plt.title('VED Predictions {}'.format(name_ds), fontsize='xx-large')\n",
    "    plt.ylabel('Prediction', fontsize ='xx-large')\n",
    "    plt.xlabel('Background Truth', fontsize ='xx-large')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "483f37ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sorted_vs_true(y_pred, y_test, name_ds):\n",
    "\n",
    "    plt_1 = plt.figure(figsize=(10, 6))\n",
    "\n",
    "    plt.plot(np.sort(y_test.flatten()))\n",
    "    x_idx = np.arange(len(y_test.flatten()))\n",
    "    plt.scatter(x_idx, y_pred.flatten()[np.argsort(y_test.flatten())], s=2, c=\"red\")\n",
    "\n",
    "    plt.title('Sorted Predictions of Validation Set {}'.format(name_ds), fontsize='xx-large')\n",
    "    plt.ylabel('Prediction', fontsize ='xx-large')\n",
    "    plt.xlabel('Background Truth', fontsize ='xx-large')\n",
    "    plt.legend(['Sorted Background Truth', 'Predictions'], loc='upper right', fontsize ='xx-large')\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66611cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_1TTI(y_test, y_pred, X_test, samp_num, name_ds): \n",
    "\n",
    "    plt_1 = plt.figure(figsize=(10, 6))\n",
    "    sample_1 = np.r_[ y_test[samp_num,], X_test[samp_num,]]\n",
    "    idx = np.arange(len(sample_1))\n",
    "    plt.scatter(np.arange(len(sample_1)), sample_1, s=2, c=\"black\")\n",
    "    plt.scatter(idx[-len(y_pred[samp_num,]):], y_pred[samp_num,], color='red',  s=2)\n",
    "    plt.title('Prediction of TTI n={} {}'.format(samp_num, name_ds) , fontsize ='xx-large')\n",
    "    plt.legend(['Background Truth', 'Predictions'],labelcolor = ['black', 'red'] ,loc='upper right', fontsize ='xx-large')\n",
    "    plt.ylabel('Feature', fontsize ='xx-large')\n",
    "    plt.xlabel('Amplitude', fontsize ='xx-large')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50d82723",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_modeling_prediction_error(data, y_test, y_pred, name_ds, nbins):\n",
    "\n",
    "    plt_1 = plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Error to be fitted\n",
    "    data = y_test.flatten() - y_pred.flatten()\n",
    "\n",
    "    # Fit of Normal Distribution\n",
    "    _, bins, _ = plt.hist(data, nbins, density=1, alpha=0.5)\n",
    "    mu, sigma = scipy.stats.norm.fit(data)\n",
    "    best_fit_line = scipy.stats.norm.pdf(bins, mu, sigma)\n",
    "\n",
    "\n",
    "    # Fit of Student-t\n",
    "    param = scipy.stats.t.fit(data)\n",
    "    pdf_fitted = scipy.stats.t.pdf(data, loc=param[1], scale=param[2], df=param[0])\n",
    "\n",
    "    plt.title('Histogram of the prediction error of VED {}'.format(name_ds), fontsize='xx-large')\n",
    "    plt.plot(bins, best_fit_line, c='red')\n",
    "    plt.scatter(data, pdf_fitted, s=2, c='green')\n",
    "    plt.legend(['Normal Fitted Curve', 'Student-T Fitted Curve'],\n",
    "               labelcolor = ['red', 'green'],  loc='upper right', fontsize ='xx-large')\n",
    "    plt.xlim([-0.6, 0.6])\n",
    "    plt.xticks(fontsize='x-large')\n",
    "    plt.yticks(fontsize='x-large')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e572fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_MPC_overtime(data, mpc, name_ds, Real):\n",
    "    \n",
    "    if Real:\n",
    "        plt.plot(data[:,0], label='1st MPC SB1')\n",
    "        plt.plot(data[:, mpc*2], label='1st MPC SB2')\n",
    "        plt.plot(data[:, mpc*4], label='1st MPC SB3')\n",
    "        plt.plot(data[:, mpc*6], label='1st MPC SB4')\n",
    "\n",
    "\n",
    "        plt.title('plot of 1st MPC in 4 subbands Over Time (Real Part) {}'.format(name_ds),  fontsize='xx-large')\n",
    "        plt.xlabel('TTI', fontsize='xx-large')\n",
    "        plt.ylabel('Amplitude', fontsize='xx-large')\n",
    "        plt.legend(fontsize='xx-large')\n",
    "        plt.tight_layout()\n",
    "        plt.show() \n",
    "    \n",
    "    else:\n",
    "        plt.plot(data[:,mpc], label='1st MPC SB1')\n",
    "        plt.plot(data[:,mpc*3], label='1st MPC SB2')\n",
    "        plt.plot(data[:,mpc*5], label='1st MPC SB3')\n",
    "        plt.plot(data[:,mpc*7], label='1st MPC SB4')\n",
    "\n",
    "\n",
    "        plt.title('plot of 1st MPC in 4 subbands Over Time (Imaginary Part) {}'.format(name_ds),  fontsize='xx-large')\n",
    "        plt.xlabel('TTI', fontsize='xx-large')\n",
    "        plt.ylabel('Amplitude', fontsize='xx-large')\n",
    "        plt.legend(fontsize='xx-large')\n",
    "        plt.tight_layout()\n",
    "        plt.show() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
